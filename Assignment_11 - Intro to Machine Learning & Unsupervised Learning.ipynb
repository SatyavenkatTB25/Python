{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1Q) Create a Minkowski distance matrix for the following iris flowers classification data. Output two tables, one for Manhattan distance and one for Euclidean\n",
    "\n",
    " Flower  | Sepal length    | Sepal width | Petal length    | Petal width | Type\n",
    "---------+-----------------+-------------+-----------------+-------------+-----------------\n",
    " Flower1 | 5.1             | 3.5         | 1.4             | 0.2         | Iris setosa\n",
    " Flower2 | 4.9             | 3.0         | 1.4             | 0.2         | Iris versicolor\n",
    " Flower3 | 7.0             | 3.2         | 4.7             | 1.4         | Iris versicolor\n",
    " Flower4 | 6.4             | 3.2         | 4.5             | 1.5         | Iris setosa\n",
    " Flower5 | 6.3             | 3.3         | 6.0             | 2.5         | Iris setosa\n",
    " Flower6 | 5.8             | 2.7         | 5.1             | 1.9         | Iris versicolor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tabulate in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (0.9.0)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.2.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m23.3.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip3 install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install tabulate\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Manhattan Distance Matrix:\n",
      "+----------+-----------+-----------+-----------+-----------+-----------+-----------+\n",
      "| Flower   |   Flower1 |   Flower2 |   Flower3 |   Flower4 |   Flower5 |   Flower6 |\n",
      "|----------+-----------+-----------+-----------+-----------+-----------+-----------|\n",
      "| Flower1  |       0   |       0.7 |       6.7 |       6   |       8.3 |       6.9 |\n",
      "| Flower2  |       0.7 |       0   |       6.8 |       6.1 |       8.6 |       6.6 |\n",
      "| Flower3  |       6.7 |       6.8 |       0   |       0.9 |       3.2 |       2.6 |\n",
      "| Flower4  |       6   |       6.1 |       0.9 |       0   |       2.7 |       2.1 |\n",
      "| Flower5  |       8.3 |       8.6 |       3.2 |       2.7 |       0   |       2.6 |\n",
      "| Flower6  |       6.9 |       6.6 |       2.6 |       2.1 |       2.6 |       0   |\n",
      "+----------+-----------+-----------+-----------+-----------+-----------+-----------+\n",
      "\n",
      "Euclidean Distance Matrix:\n",
      "+----------+-----------+-----------+-----------+-----------+-----------+-----------+\n",
      "| Flower   |   Flower1 |   Flower2 |   Flower3 |   Flower4 |   Flower5 |   Flower6 |\n",
      "|----------+-----------+-----------+-----------+-----------+-----------+-----------|\n",
      "| Flower1  |  0        |  0.538516 |  4.00375  |  3.61663  |   5.28488 |   4.20833 |\n",
      "| Flower2  |  0.538516 |  0        |  4.09634  |  3.68646  |   5.33854 |   4.18091 |\n",
      "| Flower3  |  4.00375  |  4.09634  |  0        |  0.640312 |   1.84391 |   1.44914 |\n",
      "| Flower4  |  3.61663  |  3.68646  |  0.640312 |  0        |   1.80831 |   1.06301 |\n",
      "| Flower5  |  5.28488  |  5.33854  |  1.84391  |  1.80831  |   0       |   1.33417 |\n",
      "| Flower6  |  4.20833  |  4.18091  |  1.44914  |  1.06301  |   1.33417 |   0       |\n",
      "+----------+-----------+-----------+-----------+-----------+-----------+-----------+\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tabulate import tabulate\n",
    "\n",
    "# Create a DataFrame for the iris flower data\n",
    "data = {\n",
    "    'Flower': ['Flower1', 'Flower2', 'Flower3', 'Flower4', 'Flower5', 'Flower6'],\n",
    "    'Sepal length': [5.1, 4.9, 7.0, 6.4, 6.3, 5.8],\n",
    "    'Sepal width': [3.5, 3.0, 3.2, 3.2, 3.3, 2.7],\n",
    "    'Petal length': [1.4, 1.4, 4.7, 4.5, 6.0, 5.1],\n",
    "    'Petal width': [0.2, 0.2, 1.4, 1.5, 2.5, 1.9],\n",
    "    'Type': ['Iris setosa', 'Iris versicolor', 'Iris versicolor', 'Iris setosa', 'Iris setosa', 'Iris versicolor']\n",
    "}\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Function to calculate Minkowski distance\n",
    "def minkowski_distance(x, y, p=2):\n",
    "    return sum(np.abs(x - y) ** p) ** (1/p)\n",
    "\n",
    "# Calculate Minkowski distance matrix for Manhattan distance (p=1)\n",
    "manhattan_distance_matrix = np.zeros((len(df), len(df)))\n",
    "\n",
    "for i in range(len(df)):\n",
    "    for j in range(len(df)):\n",
    "        manhattan_distance_matrix[i, j] = minkowski_distance(df.iloc[i, 1:5], df.iloc[j, 1:5], p=1)\n",
    "\n",
    "# Calculate Minkowski distance matrix for Euclidean distance (p=2)\n",
    "euclidean_distance_matrix = np.zeros((len(df), len(df)))\n",
    "\n",
    "for i in range(len(df)):\n",
    "    for j in range(len(df)):\n",
    "        euclidean_distance_matrix[i, j] = minkowski_distance(df.iloc[i, 1:5], df.iloc[j, 1:5], p=2)\n",
    "\n",
    "# Create DataFrames for distance matrices\n",
    "manhattan_df = pd.DataFrame(manhattan_distance_matrix, index=df['Flower'], columns=df['Flower'])\n",
    "euclidean_df = pd.DataFrame(euclidean_distance_matrix, index=df['Flower'], columns=df['Flower'])\n",
    "\n",
    "# Display the distance matrices in tabular format\n",
    "print(\"Manhattan Distance Matrix:\")\n",
    "print(tabulate(manhattan_df, headers='keys', tablefmt='psql'))\n",
    "print(\"\\nEuclidean Distance Matrix:\")\n",
    "print(tabulate(euclidean_df, headers='keys', tablefmt='psql'))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " 2Q) The file Athletes.xlsx Download Athletes.xlsxcontains a list of athletes from two different sports. Read the file and create a feature vector to use in comparing athletes. Notice you may need to make some data conversions and/or eliminate certain features. Do this in python - do not alter the file directly! Document your feature engineering in a Markdown cell.\n",
    "\n",
    "Calculate a dissimilarity measure for each pair of athletes and determine two groups. For this assignment this can simply be down by taking the mean of the dissimilarity scores between the first athlete and all the others. Grouping by whether an athlete falls above or below the mean.\n",
    "\n",
    "The output should be two lists; one for each group. Don't create a table, nobody wants to look at a 50x50 table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Group 1 (Below Mean Dissimilarity):\n",
      "['Alberto Bettiol', 'Alex Howes', 'Álvaro Odriozola', 'Daniel Carvajal', 'Eden Hazard', 'Federico Valverde', 'Ferland Mendy', 'James Rodríguez', 'Jimmy Whelan', 'Joe Dombroski', 'Jonathan Caicedo', 'José I.\\xa0Fernández', 'Lachlan Morton', 'Lawson Craddock', 'Logan Owen', 'Lucas Vázquez', 'Luis Villalobos', 'Luka Modric', 'Marcelo Vieira da Silva', 'Marco Asensio', 'Mariano Díaz', 'Matti Breschel', 'Mitch Docker', 'Moreno Hofland', 'Nate Brown', 'Rodrygo Goes', 'Sacha Modela', 'Sean Bennet', 'Sebastian Langeveld', 'Simon Clark', 'Tanel Kangert', 'Tejay van Garderen', 'Toni\\xa0Kroos', 'Vinicius Paixao de Oliveira ']\n",
      "\n",
      "Group 2 (Above Mean Dissimilarity):\n",
      "['Alphonse  Areola', 'Brahim Díaz', 'Carlos Henrique Casimiro', 'Dan McLay', 'Dani Martinez', 'Éder Gabriel', 'Francisco Román  Alarcón', 'Gareth Bale', 'Hugh Carthy', 'Julius van der Berg', 'Karim Benzema', 'Luka Jović', 'Mike Woods', 'Raphaël\\xa0Varane', 'Rigoberto Uran', 'Sep Vanarcke', 'Sergio Higuita', 'Sergio Ramos', 'Taylor Phinney', 'Thibaut Courtois', 'Tom Scully']\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import pairwise_distances\n",
    "import numpy as np\n",
    "\n",
    "# Read the Excel file\n",
    "df = pd.read_excel(\"/Users/tbs/Downloads/Athletes.xlsx\")\n",
    "\n",
    "# Feature Engineering (if needed)\n",
    "# In this example, we'll perform minimal feature engineering since the dataset structure is not provided.\n",
    "\n",
    "# Normalize numeric features (if needed)\n",
    "numeric_features = df.select_dtypes(include=[np.number]).columns\n",
    "scaler = MinMaxScaler()\n",
    "df[numeric_features] = scaler.fit_transform(df[numeric_features])\n",
    "\n",
    "# Calculate Dissimilarity Measure\n",
    "\n",
    "# Calculate dissimilarity matrix using pairwise_distances (Euclidean distance)\n",
    "dissimilarity_matrix = pairwise_distances(df[numeric_features], metric='euclidean')\n",
    "\n",
    "# Calculate the mean dissimilarity score for the first athlete\n",
    "mean_dissimilarity = np.mean(dissimilarity_matrix[0, 1:])\n",
    "\n",
    "# Group Athletes Based on Dissimilarity Scores\n",
    "\n",
    "# Group athletes based on their dissimilarity scores\n",
    "group1 = [athlete for i, athlete in enumerate(df['Athlete']) if dissimilarity_matrix[0, i] <= mean_dissimilarity]\n",
    "group2 = [athlete for i, athlete in enumerate(df['Athlete']) if dissimilarity_matrix[0, i] > mean_dissimilarity]\n",
    "\n",
    "# Display the two athlete groups\n",
    "print(\"Group 1 (Below Mean Dissimilarity):\")\n",
    "print(group1)\n",
    "print(\"\\nGroup 2 (Above Mean Dissimilarity):\")\n",
    "print(group2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3Q) (Analysis) We want to see if there types of flights that get delayed. Review delayed_flights.csv  downloadPreview the document to determine which features might contribute to grouping flights. Document them in a Markdown cell "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Following features contribute to grouping flights:-\n",
    "\n",
    "Departure Delay, Arrival Delay, Air System Delay, Security Delay, Airline Delay, Late Aircraft Delay and Weather Delay \n",
    "Below is the code to determine delayed flights "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['YEAR', 'MONTH', 'DAY', 'DAY_OF_WEEK', 'AIRLINE', 'FLIGHT_NUMBER',\n",
       "       'TAIL_NUMBER', 'ORIGIN_AIRPORT', 'DESTINATION_AIRPORT',\n",
       "       'SCHEDULED_DEPARTURE', 'DEPARTURE_TIME', 'DEPARTURE_DELAY', 'TAXI_OUT',\n",
       "       'WHEELS_OFF', 'SCHEDULED_TIME', 'ELAPSED_TIME', 'AIR_TIME', 'DISTANCE',\n",
       "       'WHEELS_ON', 'TAXI_IN', 'SCHEDULED_ARRIVAL', 'ARRIVAL_TIME',\n",
       "       'ARRIVAL_DELAY', 'DIVERTED', 'CANCELLED', 'CANCELLATION_REASON',\n",
       "       'AIR_SYSTEM_DELAY', 'SECURITY_DELAY', 'AIRLINE_DELAY',\n",
       "       'LATE_AIRCRAFT_DELAY', 'WEATHER_DELAY'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Read the delayed_flights.csv file and store it in a DataFrame\n",
    "delayed_flights = pd.read_csv('/Users/tbs/Downloads/delayed_flights.csv')\n",
    "\n",
    "# Display the column names (features) of the DataFrame\n",
    "delayed_flights.columns\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4Q) (Execution) Read the file and process only those features you identified in 1a. Use k-means clustering to separate the delayed groups into two clusters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/cluster/_kmeans.py:1416: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  super()._check_params_vs_input(X, default_n_init=10)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total flights were delayed in the first cluster: 306\n",
      "Total flights were delayed in the second cluster: 2681\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "# Read the \"delayed_flights.csv\" file into a DataFrame\n",
    "delayed_flights = pd.read_csv('/Users/tbs/Downloads/delayed_flights.csv')\n",
    "\n",
    "# Select the relevant features for clustering\n",
    "features = delayed_flights[['DEPARTURE_DELAY', 'ARRIVAL_DELAY', 'AIR_SYSTEM_DELAY', 'SECURITY_DELAY', 'AIRLINE_DELAY', 'LATE_AIRCRAFT_DELAY', 'WEATHER_DELAY']]\n",
    "\n",
    "# Initialize the K-Means model with the desired number of clusters (2 in this case)\n",
    "clusters = KMeans(n_clusters=2).fit(features)\n",
    "\n",
    "# Initialize variables for tracking cluster assignments\n",
    "location = 0\n",
    "cluster1, cluster2 = [], []\n",
    "\n",
    "# Assign each flight to the appropriate cluster based on cluster labels\n",
    "for i in clusters.labels_:\n",
    "    if i == 0:\n",
    "        cluster1.append(delayed_flights.iloc[location])\n",
    "        location += 1\n",
    "    else:\n",
    "        cluster2.append(delayed_flights.iloc[location])\n",
    "        location += 1\n",
    "\n",
    "# Display the number of flights in each cluster\n",
    "print('Total flights were delayed in the first cluster:', len(cluster1))\n",
    "print('Total flights were delayed in the second cluster:', len(cluster2))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " 5. (Analysis) Review two or three of the flights in each cluster and estimate why those flights were in the same cluster (2 points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First flight features from Cluster 1:\n",
      "DEPARTURE_DELAY        148\n",
      "ARRIVAL_DELAY          128\n",
      "AIR_SYSTEM_DELAY         0\n",
      "SECURITY_DELAY           0\n",
      "AIRLINE_DELAY            0\n",
      "LATE_AIRCRAFT_DELAY      0\n",
      "WEATHER_DELAY          128\n",
      "Name: 13, dtype: object\n",
      "\n",
      "Second flight features from Cluster 1:\n",
      "DEPARTURE_DELAY        213\n",
      "ARRIVAL_DELAY          226\n",
      "AIR_SYSTEM_DELAY        13\n",
      "SECURITY_DELAY           0\n",
      "AIRLINE_DELAY            0\n",
      "LATE_AIRCRAFT_DELAY      0\n",
      "WEATHER_DELAY          213\n",
      "Name: 22, dtype: object\n",
      "\n",
      "Third flight features from Cluster 1:\n",
      "DEPARTURE_DELAY        119\n",
      "ARRIVAL_DELAY          116\n",
      "AIR_SYSTEM_DELAY         0\n",
      "SECURITY_DELAY           0\n",
      "AIRLINE_DELAY            0\n",
      "LATE_AIRCRAFT_DELAY      0\n",
      "WEATHER_DELAY          116\n",
      "Name: 24, dtype: object\n",
      "\n",
      "First flight features from Cluster 2:\n",
      "DEPARTURE_DELAY        12\n",
      "ARRIVAL_DELAY          25\n",
      "AIR_SYSTEM_DELAY       25\n",
      "SECURITY_DELAY          0\n",
      "AIRLINE_DELAY           0\n",
      "LATE_AIRCRAFT_DELAY     0\n",
      "WEATHER_DELAY           0\n",
      "Name: 0, dtype: object\n",
      "\n",
      "Second flight features from Cluster 2:\n",
      "DEPARTURE_DELAY        72\n",
      "ARRIVAL_DELAY          43\n",
      "AIR_SYSTEM_DELAY       43\n",
      "SECURITY_DELAY          0\n",
      "AIRLINE_DELAY           0\n",
      "LATE_AIRCRAFT_DELAY     0\n",
      "WEATHER_DELAY           0\n",
      "Name: 1, dtype: object\n",
      "\n",
      "Third flight features from Cluster 2:\n",
      "DEPARTURE_DELAY         0\n",
      "ARRIVAL_DELAY          15\n",
      "AIR_SYSTEM_DELAY        0\n",
      "SECURITY_DELAY          0\n",
      "AIRLINE_DELAY          15\n",
      "LATE_AIRCRAFT_DELAY     0\n",
      "WEATHER_DELAY           0\n",
      "Name: 2, dtype: object\n"
     ]
    }
   ],
   "source": [
    "# Define the list of features for printing flight details\n",
    "features = ['DEPARTURE_DELAY', 'ARRIVAL_DELAY', 'AIR_SYSTEM_DELAY', 'SECURITY_DELAY', 'AIRLINE_DELAY', 'LATE_AIRCRAFT_DELAY', 'WEATHER_DELAY']\n",
    "\n",
    "# Print the features of the first three flights in Cluster 1\n",
    "print('First flight features from Cluster 1:')\n",
    "print(cluster1[0][features])\n",
    "print('\\nSecond flight features from Cluster 1:')\n",
    "print(cluster1[1][features])\n",
    "print('\\nThird flight features from Cluster 1:')\n",
    "print(cluster1[2][features])\n",
    "\n",
    "# Print the features of the first three flights in Cluster 2\n",
    "print('\\nFirst flight features from Cluster 2:')\n",
    "print(cluster2[0][features])\n",
    "print('\\nSecond flight features from Cluster 2:')\n",
    "print(cluster2[1][features])\n",
    "print('\\nThird flight features from Cluster 2:')\n",
    "print(cluster2[2][features])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In Cluster 1, the flights seem to have longer delays and are primarily influenced by weather-related delays.\n",
    "In Cluster 2, the flights have shorter delays and appear to be influenced by air system delays or airline delays."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
